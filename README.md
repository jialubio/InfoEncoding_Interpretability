# Interpretable ML for pattern classification

Biological patterns, such as colony morphology, can be leveraged to [encode real-world information through classification](https://doi.org/10.1016/j.patter.2022.100590). A machine learning-based decoder has been developed to extract common features across morphologies from different classes of images. To gain insights into the key features recognized by the ML model, interpretability algorithms such as **saliency maps, activation map, and common high-excitation maps** have been applied.

Furthermore, branching pattern development is viewed as a noise amplification process in biology. The application of interpretable ML techniques has also been instrumental in verifying the extent to which information is preserved throughout this dynamic process.

Supporting the hypothesis, the colony center was consistently highlighted as the primary region of interest, indicating its crucial role in classification by the CNN. This also confirms that the initial cell seeding configuration (i.e., the location where cells were first inoculated) is preserved and this information is not lost during colony development.

[Reference](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Ahmed_An_Improved_Deep_2015_CVPR_paper.pdf
![image](https://github.com/user-attachments/assets/7e4eda74-5f9a-4198-b428-52ee4faa27c4)
)

